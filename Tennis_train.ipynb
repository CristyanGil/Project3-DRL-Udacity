{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "---\n",
    "The goal for this project is to solve the environment [**Tennis**](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#tennis) using a [**Multi-Agent DDPG**](https://papers.nips.cc/paper/7217-multi-agent-actor-critic-for-mixed-cooperative-competitive-environments.pdf) approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the environment\n",
    "\n",
    "The first thing to do is to import the unity environment and the wrapper to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "state_size: 48 obs_size: 24  action_size: 2\n"
     ]
    }
   ],
   "source": [
    "from environment import Env\n",
    "env = Env(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library that contains the agent handler\n",
    "Let's import the library MADDP that will help us to initialize the agents.\n",
    "Here we are going to get the actors and the critics for both agents involved in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddpg import MADDPG\n",
    "maddpg = MADDPG(env.state_size, env.obs_size, env.action_size, env.num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer Module\n",
    "Here we can set the batch size of the buffer, in this case, I set it to 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buffer import ReplayBuffer\n",
    "BATCH_SIZE = 1024\n",
    "buffer = ReplayBuffer(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents Architectures\n",
    "Let's print the actor and critic architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ActorNetwork(\n",
      "  (fc1): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      "), ActorNetwork(\n",
      "  (fc1): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      ")]\n",
      "[CriticNetwork(\n",
      "  (fcs1): Linear(in_features=48, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=260, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      "), CriticNetwork(\n",
      "  (fcs1): Linear(in_features=48, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=260, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "print(maddpg.get_actors())\n",
    "print(maddpg.get_critics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights\n",
    "The next function is useful to save the weights for all of the models used. We have an actor, a target actor, a critic and a target critic for each of the two agents involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def save_weights(maddpg):\n",
    "    for num_agnt, agnt in enumerate(maddpg.maddpg_agent):\n",
    "        torch.save(agnt.actor.state_dict(),         'ckpt_actor_{}.pth'.format(num_agnt))\n",
    "        torch.save(agnt.target_actor.state_dict(),  'ckpt_target_actor_{}.pth'.format(num_agnt))\n",
    "        torch.save(agnt.critic.state_dict(),        'ckpt_critic_{}.pth'.format(num_agnt))\n",
    "        torch.save(agnt.target_critic.state_dict(), 'ckpt_target_critic_{}.pth'.format(num_agnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n",
    "\n",
    "It is time to import the libraries that we will need, such as gym torch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for the training\n",
    "Here you can set the number of episodes, the episode that you want the agent to be trained, and the scores and means scores lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 2000\n",
    "episode_per_update = 1\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "mean_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the agent\n",
    "\n",
    "Now, It is time to train the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000: Average Score 0.17270000265911223, Score (max over agents) 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "for episode in range(1, num_episodes+1):                                      # play game for num_episodes\n",
    "    #print(\"Episode: \", i)\n",
    "    for agent in maddpg.maddpg_agent:\n",
    "        agent.noise.reset()\n",
    "    clear_output(wait=True)\n",
    "    obs, state = env.reset(train_mode=True)                          # reset the environment \n",
    "    local_scores = np.zeros(env.num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        #actions = np.random.randn(env.num_agents, env.action_size)  # select an action (for each agent)\n",
    "        actions = maddpg.act(obs)\n",
    "        actions = [ a.cpu().data.numpy() for a in actions]\n",
    "        #print(actions)\n",
    "        next_obs, next_state, rewards, dones = env.execute(actions)           # send all actions to the environment\n",
    "        \n",
    "        buffer.push(obs, state, actions, rewards, next_obs, next_state, dones)\n",
    "        \n",
    "        local_scores += rewards                         # update the score (for each agent)\n",
    "        obs, state = next_obs, next_state                               # roll over states to next time step\n",
    "        \n",
    "        \n",
    "        #if len(buffer) > batchsize and episode % episode_per_update < parallel_envs:\n",
    "        if len(buffer) > BATCH_SIZE and episode%episode_per_update==0:\n",
    "            #clear_output(wait=True)\n",
    "            for a_i in range(env.num_agents):\n",
    "                #print(\"agent: \", a_i)\n",
    "                samples = buffer.sample()\n",
    "                #maddpg.update(samples, a_i, logger)\n",
    "                maddpg.update(samples, a_i)\n",
    "            maddpg.update_targets() #soft update the target network towards the actual networks\n",
    "            #print(\"Updated...\")\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    episode_reward = np.max(local_scores)\n",
    "    scores.append(episode_reward)\n",
    "    scores_deque.append(episode_reward)\n",
    "    avg_score = np.mean(scores_deque)\n",
    "    mean_scores.append( avg_score )\n",
    "    #print('Score (max over agents) from episode {}: {}'.format(episode, episode_reward ))\n",
    "    print('Episode {}: Average Score {}, Score (max over agents) {}'.format(episode, avg_score, episode_reward ))\n",
    "    if len(mean_scores) >= 100:\n",
    "        if np.mean(mean_scores[-100]) >= 0.5: #condition for considering the environment as solved\n",
    "            print(\"Enrironment solved in {} episodes!!!\".format(episode) )\n",
    "    if episode_reward >=  np.max(scores):\n",
    "        save_weights(maddpg)\n",
    "        print(\"The models has been saved!\")\n",
    "#print(\"Mean Score: \", np.mean(scores_deque) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "The final part is just to plot the results, we have a red line that shows the performance of the model across the episodes and a blue line that indicates the minimum value to consider the environment solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcHFW5//HPk30nIQkIhJAEwhIQCEYMIoiGJWzhhyC7uHDBDUW83p8siuACKgJeFbiC4IICAoIGDbIIKHLZQsKSAIFhMSuYQEggk3Xy3D+erpmeSc9Mz0xXd1fP9/16zetUV1dXPamZ1NPnnKpzzN0REREB6FHpAEREpHooKYiISCMlBRERaaSkICIijZQURESkkZKCiIg0UlIQEZFGSgoiItJISUFERBr1qnQAHTVixAgfM2ZMpcMQEcmUJ598cpm7j2xvu8wlhTFjxjBz5sxKhyEikilm9q9itlPzkYiINFJSEBGRRkoKIiLSSElBREQaKSmIiEgjJQUREWmkpCAiIo2UFESkNi1aBBdfDC++WOlIMiVzD6+JiLRrwwYYNSqWzz8fNBd90VRTEJHa81//1bQ8cWLl4sggJQURqT0//nHT8tixlYsjg5QURKT2jBsXZZ8+sHp1ZWPJGPUpiEjt6dsXjjkG3ngD7roL1q+H3r0rHVUmqKYgIrVl6VJ4/nkYPTp+AJYtq2xMGaKkICK15cEHo/zIR+CII2J55cqKhZM1SgoiUlvefjvKiRNhxIhYnj+/cvFkjJKCiNSWpUujHDKk6XbUOXMqF0/GqKNZRGrHv/4VD6sNGACDBoEZDB8OTzxR6cgyQ0lBRGrHVVdFOXQo9Mg1hIwd29SkJO1S85GI1I7hw6O8446mdQMHwqpVlYkng5QURKR2bNgQ5R57NK0bMADq6ysTTwYpKYhI7UieXu7Tp2mdagodoqQgIrXjb3+Dfv2igzkxYICSQgcoKYhI7aivhzFjmq8bOFDNRx2gpCAitWH9enjmGTj00Obr1XzUIUoKIpJ9GzfCpz4Vk+kkk+skBgyIvoaNGysSWtakmhTMbKqZzTOzOjM7p8D7o83sATObbWbPmNlhacYjIjXqjTfgxhtjeeDA5u8lrzWEdlFSe3jNzHoCVwIHAQuBJ8xsurs/l7fZN4Bb3P1qM5sAzADGpBWTiNSgu+6CW25pet3Q0Pz9AQOifPfdTROGbCLNJ5r3Burc/RUAM7sZOArITwoODMktbwYsTjEeEalFh7VoYDjuuOavkyebZ8+GqVPLE1OGpZkUtgEW5L1eCHygxTYXAveY2ZeAgcCBKcYjIrVuxYoYCC/f3ntHuXZt+ePJoDT7FKzAOm/x+kTgV+4+CjgMuMHMNonJzM4ws5lmNnNpMgKiiMjrrzctT5u2aUIA9Sl0UJpJYSGwbd7rUWzaPHQacAuAuz8C9ANGtNyRu1/j7pPcfdLIkSNTCldEMufWW6Pcemv4058Kb9OvX5Rr1pQnpoxLMyk8AYw3s7Fm1gc4AZjeYpv5wBQAM9uFSAqqCohIcWbOjPKee1rfpn//KFVTKEpqScHdNwBnAncDzxN3Gc01s2+b2bTcZv8JnG5mTwM3AZ9y95ZNTCIihb39Nuy5J+y6a+vbqKbQIanOp+DuM4jbTPPXXZC3/Bywb5oxiEgNW7266aLfmqSm8Je/wNlnpx9TxumJZhHJrjVrmi76rUlGTP3b32DlyvRjyjglBRHJrmJqCvkjpi5Y0Pp2AigpiEiWrV7dfk0hnwbGa5eSgohk15o17dcUAD7/+abtpU1KCiKSXcXWFE46KUo91dwuJQURya5i+hQA+vaNUkmhXUoKIpJNDQ0x8umgQe1vmySOJ59MN6YaoKQgItm0ZEnMttZy+s1CdtwxygUL4oE3aZWSgohkUzJsxeDB7W/bty9ssw1cdx1ssUW6cWWckoKIZFNyJ1HSX9Ce4cOjXL8+nXhqhJKCiGRT8iBasUlhs83Si6WGKCmISDZ94hNRzptX3PazZ6cXSw1RUhCRbEo6mLffvrjt99kntVBqiZKCiGTT0UdHecQRxW1//fVNyxqhv1VKCiKSTWvXxmB3vYqcAWDUKPje92J53br04so4JQURyaZk3CMrNB18KzQLW7uUFEQkm9auLf7Oo0SSFOrrSx9PjVBSEJFsKnaE1HxJUvjZz0ofT41QUhCRbOpMTSF5mvmSS+Dll0sfUw1QUhCRbOpMUjj44Oafl00oKYhINnWm+ahnz6blhobSxlMjlBREJJs6U1PIp1nYClJSEJFs6mpS0B1IBSkpiEg2dab5KN+qVaWLpYYoKYhINqmmkAolBRHJps7WFHbfPcpHHiltPDVCSUFEsqmzNYVZs0ofSw1RUhCRbOpsUujZM2Zh091HBSkpiEg2daWjuV8/PbzWCiUFEcmmrnQ09+2rmkIrlBREJJu6khT69VNSaIWSgohkz8aNMVFOZ5uP+vZV81ErlBREJHuSmdNUUyg5JQURyZ7kgq6aQskpKYhI9iQXdNUUSi7VpGBmU81snpnVmdk5rWxznJk9Z2ZzzezGNOMRkRpRiqSgmkJBvdLasZn1BK4EDgIWAk+Y2XR3fy5vm/HAucC+7r7czLZIKx4RqSHvvBOlbkktuTRrCnsDde7+iruvA24GjmqxzenAle6+HMDd/51iPCJSK+6/P8oVKzr3eTUftSrNpLANsCDv9cLcunw7Ajua2cNm9qiZTU0xHhGpFYMHRzllSuc+r47mVqXWfARYgXVe4PjjgQOAUcBDZrabu7/dbEdmZwBnAIwePbr0kYpItiQX9CFDOvd51RRalWZNYSGwbd7rUcDiAtv8yd3Xu/urwDwiSTTj7te4+yR3nzRy5MjUAhaRjFi9Osr+/Tv3edUUWpVmUngCGG9mY82sD3ACML3FNn8EPgJgZiOI5qRXUoxJRGpBV5NCUlPwlo0XklpScPcNwJnA3cDzwC3uPtfMvm1m03Kb3Q28aWbPAQ8A/+Xub6YVk4jUiNWrwaxrt6QCrF9fuphqRJp9Crj7DGBGi3UX5C078NXcj4hIcZJhs61Q12URkmSyZg306VO6uGqAnmgWkexZtAh69+7855OagvoVNqGkICLZc+ONsHJl5z+fX1PIt2gR/PjH0NDQ+X1nnJKCiGRLKTqHk5pCy6Rw2WVw9tnw4INdP0ZGKSmISLYkw2ZffHHn95HUFFo2H72Su/kxGUajG1JSEJFseffdKAcN6vw+Wqsp9Mrde/P6653fd8YpKYhItqxaFeXAgZ3fR2s1heQJ6QsuoLtSUhCRbEmzppCsHzCg8/vOOCUFEcmWurooS5EUHn20+fquPildA5QURCRbHn44yp137vw+dtstyh4tLoFJUnjhBfjjHzu//wxTUhCRbFm1CoYNg3HjOr+PpCbQsvmovr5p+aqrOr//DFNSEJFsWbu282MeJcwKD5/99tsweTKMGAH33gvHHNO142SQkoKIZEspkgIUTgqvvhrNUtdfH69vvx1mzuz6sTJESUFEsqVUSaF//6Y7mRJr1sSdR0ce2dQJ/eqrXT9WhigpiEi2lCopbLstzJ/ffN2aNU37TmZ5vOeerh8rQ5QURCRbSpUUhg7ddDiL/H2/5z1RbtzY9WNliJKCiGRLKZuPkltQIS7+69c3PcNgBrvsAg891PVjZUjRk+yY2YeA8e7+SzMbCQzKzaucCV/5Cjz1VKWjEJEum/2jeL7ggC7u57mL4d13Yj8bG+CNN4AH4FdjYx5IgMW/gxUrYI/lcRtshe25Z4zsnaaiagpm9i3g68C5uVW9gd+mFZSISKs2+qYPnXVGjx5NTUNLXocXX4zl4Zs3bTNhQpTJe91AsTWFo4GJwCwAd19sZoNTiyoFaWdXESmT934KdtgB7rija/v5wk/gttvgwC/DN7/ZtP7WV2BscnnrCyf+HG6+GR7Y2PnpPzOk2HS7LjefsgOYWReGJxQR6YJSPqfw1lvNE0KyPt+kSVG2vH21RhWbFG4xs58DQ83sdOA+4Nr0whIRaUUpO5oLTbvZct/bbRfl8893/ZgZUFTzkbv/yMwOAlYCOwEXuPu9qUYmIlJIKZNCIS1rCttsE+Vbb3X9mBnQblIws57A3e5+IKBEICKVVaqk0Lt34fUt950kj/zbV2tYu81H7t4A1JvZZmWIR0SkbaVKCuPHb7pu2TLo2bP5OiWFgtYAz5rZdWb2k+QnzcBERDbx97/Hxfnxx7u+r6OPjuGxV6yI17vuCsOHb7pdMu1nNxkYr9hbUv+S+xERqZz774/y85/v+r7Mmvbz9tvQp0/h7ZI+hWef7foxM6DYjuZfm1kfYMfcqnnuvj69sERECli9OpqOTjyxtPvdrI3WcTPYZx+4777SHrNKFftE8wHAS8CVwFXAi2a2f4pxiYhs6p13YHAFnpt95JEoX365/Mcus2L7FC4DDnb3D7v7/sAhwBXphSUiUsC771YmKZybG+HnzTfLf+wyKzYp9Hb3eckLd3+RGP9IRKR83nkHBg0q/3EPPjjKVavKf+wyKzYpzMzdeXRA7uda4Mk0AxMR2cSDD1amppAkom4w1EWxdx99Hvgi8GXAgH8QfQsiIuXhDvX1lRmUTkmh4Hb/7e6XQ+NTziV4ekREpEgrV8YkOEcfXf5jd6OkUGzz0d+A/IFC+hOD4omIlEd9fZQDKzBIc5IUusG8CsUmhX7u3pgic8sD0glJRKSAtWujLMUQFx01ZEiUDz9c/mOXWbFJYZWZ7ZW8MLNJQLsDgZjZVDObZ2Z1ZnZOG9sda2ae26+IyKYqmRR69IDjjusWt6QW26fwFeBWM1tMTLSzNXB8Wx/I9TtcCRwELASeMLPp7v5ci+0GEx3Yj3UwdhHpTiqZFCDmaH777cocu4zarCmY2fvN7D3u/gSwM/B7YAPwV+DVdva9N1Dn7q+4+zrgZuCoAtt9B/ghMeieiEhhL70UZSWTwvLlcRdUDWuv+ejnwLrc8j7AecS3/+XANe18dhtgQd7rhbl1jcxsIrCtu/+52IBFpJtKvqVvtVVljj90aNz9VONDaLfXfNTT3ZPpho4HrnH3PwB/MLOn2vlsoZuJG1OsmfUghsr4VHtBmtkZwBkAo0ePbm9zEalFSfPRqFGVOf6wYVEuXw4Davc+m/ZqCj3NLEkcU4D7895rL6EsBLbNez0KWJz3ejCwG/Cgmb0GTAamF+psdvdr3H2Su08aOXJkO4cVkZpU6T6FoUOjrPF+hfYu7DcBfzezZcTdRg8BmNkOwIp2PvsEMN7MxgKLgBOAk5I33X0FMCJ5bWYPAl9z9+4xk4WIdIySQlm0WVNw9+8B/wn8CviQe2MPSw/gS+18dgNwJnA38Dxwi7vPNbNvm9m0rgYuIt1MpZNC0nz02muVOX6ZtHtLqrs/WmBdUY/1ufsMYEaLdRe0su0BxexTRLqptWuhV694ZqASNt88ylNOgZNPrkwMZVChsysi0kFr11aulgAwblzM4wywpnbvoFdSEJFsqHRSMIMvfjGWa7hfQUlBRLKh0kkBmuZyWLmysnGkSElBRLJhwYLKJ4X+ucGia7j5qNixj0REKmfpUrj77kpHAf36RVnDSUE1BRGpfsuWRTmpwgMpKymIiFSB5CJ8/vmVjSNJCrfcUtk4UqSkICLVL3lwLbkoV0ryrMKVV8KSJZWNJSVKCiJS/ZKaQqU7mnfYoWl5663h3nsrF0tKlBREpPolSaHSNYXevaGhAaZOjdcXXljRcNKgpCAi1a9akgLEMBt33QVTpsAzz1Q6mpJTUhCR6lctfQr5Bg6Ed9+FVasqHUlJKSmISPWrlj6FfIceGuWK9mYRyBYlBRGpftXUfJRoaIiyxjqblRREpPrdn5v0sZqmwdx33yhrbBwkJQURqX5JMkhmP6sG48dHeeedMGdOZWMpISUFEal+9fWw006VjqK5gQNhwoRoPpo8udLRlIySgohUv/r6uAhXm+Q5hRoaC0lJQUSq36pV1dWfkPj4x+HMM2GzzSodSckoKYhI9auvr86kABFXfX2loygZJQURqX7VnBSGDYvmo9dfr3QkJaGkICLVr5qTws47R7l4cWXjKBElBRGpftXa0QwwaFCUqimIiJRJtXY0Q1NSOPxwcK9sLCWgpCAi1a+am492261p+amnKhdHiSgpiEh1W7sWNmyo3qQwaBDcd18s18DgeEoKIlLdnn8+ym22qWwcbenfP8pkiO8MU1IQkeqWfPsePbqycbQlGdJbSUFEJGXJg2HVevcRKCmIiJRNUlOo1j4FgD59olRSEBFJ2bx5UW63XWXjaEtSU1i3rrJxlICSgohUt1WroiO3mgedU/ORiEiZrFlTXdNwFqKkICJSJkoKZdWr0gGIiLTp2msrHUH71NFcHDObambzzKzOzM4p8P5Xzew5M3vGzP5mZlXckyQi0opevaBnT3j77UpH0mWpJQUz6wlcCRwKTABONLMJLTabDUxy992B24AfphWPiGRQQ0OUF11U2TiKsf32UFdX6Si6LM2awt5Anbu/4u7rgJuBo/I3cPcH3D2ZsuhRYFSK8YhI1iRzHyfDSFSz4cNh9epKR9FlaSaFbYAFea8X5ta15jTgrhTjEZEsWbYMpkyJ5SwMNFcj03Km2dFsBdYVHGzczE4BJgEfbuX9M4AzAEZX8/gnIlI6P/85PPZYLO+xR2VjKcaAAfDWW5WOosvSrCksBLbNez0K2GS+OjM7EDgfmObuBbvu3f0ad5/k7pNGjhyZSrAikoK774ZLLoH3vhfOOiuGwC5GQwNccw1suWV8+/74x9ONsxT691dNoR1PAOPNbCywCDgBOCl/AzObCPwcmOru/04xFhEpl4YGmDsXrroqvu0n5syB/faDY49tfx+LFsH8+XD00dnoTwA1H7XH3TeY2ZnA3UBP4Hp3n2tm3wZmuvt04FJgEHCrmQHMd/dpacUkIiW2fj1897vw2mtxAb/nHrj66qb3t90WLr00OmEPOggWLmx/nxs3Nt1tdMopqYSdigEDutbRvHw5DBtWung6KdWH19x9BjCjxboL8pYPTPP4IpKyD3wAZs+O5d/8pvl7f/oTTMt9x0tuLV25su39bdgAN9wA118fr7PUh9jZ5qO//x0OOCCWf/tbOPnkTbeZPh2OOSY631MeA0rDXIhI59x6aySErbeOpp4jj4Svfx0+9jH40Y+aEgLEg10DB7Z/F9FXvwqf+Uws//OfMGlSevGXWlJT8IL30zS3YUNTosxvYnvyycLbf+1r8Zk5c7oeZzs0zIWIdNw778CnPx3LL7wAgwfHt9m2DBkCr7wCF18cHcfjxzd/v74efvrTWD7pJNh339LHnaYBAyIhrF3b+lhNd94Jf/1r9LcAHHJIdMbvuGN87oorYpsxY+C882DvvWHWLHjppdh+6NDU/xlKCiLSMevXw3veExfxM8+MhFCMjRvhj3+MnzffhMsua/7+McdEeeih8ItflDbmckg6xFevLpwU5s5tXnuCSAgAp54aT0SfeGI8FV1XB/fdF+/tuWeU558Pu+6aTux5lBREpGPq6+Nnv/3gJz8p/nMf/GB8S169OhJLvttvj/cALr88O3cc5Utmhquvb95hvGhRjI30vvc1rXvqqWhSu+IKmDwZTj891h9/fDzrMGJE821POQW+8530/w2oT0FEOioZeuKEE8AKPaPaittuiz6F97ynaR+J666L8s47YeedSxNnuSVJIUluEAlw1Kj4N69dG8vu8TDebrvFvztJCBDnc/hw+OY3m+/7vPM6dq67QElBRDomGR46mUOgWD16QO/eUQuoq4vmJIjO5Rkz4tv1EUeUNtZySmo///EfcY7WrWs+r/RnPxu37hbjootixNUXXoiaxi67lDzc1qj5SEQ6JkkKnZ34ZvFiePXVaE665JJoQgH4/vdLE1+l5Nd+/vznaPZJPPJI3L5b7Ld9s7j1tAJTkKqmICLF++xn404Z6HhNIXHllVE+9hh89KOxvHQpnHFG1+OrpPy7qZYsiYf6IGpBkyeXrfmnq5QURKR4t90W5ac+Bfvv37l9nHYaPP1086SS37GaVVOmwOOPx/KXvhTltGlxN1WGqPlIRIqzYUMMxfCtb8GFF3ZtX7vvDv/+d3yL3nbb9rfPipYP2116aWXi6AIlBREpztKlcefMlluWZn9DhsQdTLXELB7Q+/zno2ksaWrLECUFESnOG29EWaqkUKvGjm1+W2rGqE9BRIrzy19GqaRQ01RTEJH2feELTUNiT5hQ2VgkVUoKIrKpJUvg8MObhsVOzJlTFWP+S3rUfCQizdXXx3DY+Qnhy1+OMXnKMCCbVJZqCiLSZNGipmcRPvvZmBehf/8YvE26BSUFEQlz5sB739v0+rLLYmIc6VbUfCTS3TU0xJSQyXzIRxwR00IqIXRLqimIdMTjj0cn7Lp1UR53XAyLXE7r1sXkLPvuC5tvHk8GDx0ao3T27g19+hS3n5/8BM46q/m6yy+Hs88ufcySGUoKIsU67bSmCeUTZ50Vo2HusUd6x33rrWjaef31GGri1FOb5vdtzYknwgUXFJ6b4OWXo1bw6KPxesSIGOf/+uth4sTSxy+ZouYjkWJ89atx0Rw8OC7K55/fNOvYnnvG7ZvbbRfDHHzta7ByZdQqLr64/cnqE/X1sb1ZPBW7xRZNk658+MMxK9fJJ0dCOP30OF5iypQot946mn1uuinuFLriipi3YMkSmDkzRiLdYYdICGedFXEuXRp3GikhCGDuXukYOmTSpEk+c+bMSoch3clZZ0UC+OhH4Y47YsyexK23wle+EnMEtOVnP4sHwPKHT16zJr6x/+Uvm85EBlH7GDQIdtopJmu5884YK+jb344mouT/bqEhmWfNaj79Y75hw6IPIb9TWWqemT3p7pPa3U5JQaQN//u/0XZ/0EFw112Fb810j8no3//+mJD+xhvhhz+Mb/a//33h/e6zT0y80tLee8fFf4stuh77/PnwjW/ASy81zdx14olw4IGZGdtfSkdJQaQzGhrgqqviYa18zzzT+W/Ws2ZFs88LL2z63uWXR21hyJDOT1ojUoRik4I6mkUAbr89moJuvnnT9/7wh641tey1Fzz/fLTfr1oVdwrNnh3zCNTSXAJSE9TRLE0uuaRp2sDJk2O6RPfCd7pkrIbZKvfoND7mmEgIvXrBN78Zk8m4x8/HPlaaYw0ZAlttFU8If/CDSghSlVRTkPgmfOyxzdc99lgkhsSECbBwYVzYhg2LtvNRo6J9+qKL4mK6Zg3ccAOce250yh58cEzb2KtK/8zeeismQ7nllmjDf+QRGDMGeui7knRf6lPoLhoaotN03ry42I8aBa+9BtdeG23oEHfZ/OAHcbF85JFo73744eL2f+SRMHduzDqVb9iwaHrZsCEeitprLxg3rqT/tE658Ub49KfjQbBp06L5SOP7SA1TR7PAq69Gk9DatXDPPfHwUyE77RTflnfffdP3NmyIb/pz50ZH6LJlcf/74MHx/je+Ad/7XtP2554Ln/hE3Gd/9dXxANW772663wkTYpuHHoo7e6ZMgc99rrR3xaxeHROo//Of0Z5//PGRHP/5z2jT33zzGM4hYxOri3SGkkI1cY8LFEC/fk3NE+7p3Rp4001w0knN1519djzh+tBD0Qy03XbRlr799l071saN0ZH65puw//7N33OPC/L998N998H06dEMVcjVV0diSNTXNz9fa9fG+7/6VSSS886DAw6IC/yMGfEQVs+esbzHHvD004Xv+IFISo8/rvF9pNtQUqgGL74Y36JnzIhv2BAPI512WtyPfvLJse7006PT0T2enB00qPV9LlgQTTXLl8PUqVEbWLgwytGjo028ri6accaNixrAlltGLWFSu38P5bFqVYzRs3BhxHjXXXDYYfHegAFxblasaBrPf9ddY37g5BzmGzkykkFrvv99+PrX41gLFkQz0Zgx8Tvo16/k/zSRaqWkUEnz58cTsJddFq8nT4YPfSieQr3zTnj22dY/u+OO8YTsqac2/xb761/HPmfNavvYZjHUwTHHxDfprMyn+8YbMTpn/u+2X79Nn/T95CejxjNgQFzY16+Ph8sOPTTOTc+e8XrxYjjkkNhORJQUKiZ/5MkddojbHPOHG9i4MTp2586Fb30rLvzvvBNNGbNnxxAGiZNPjrFqrrwyvvEPHhwXumOPhd12g3/8I5pRxoyJ7ZM7gHr3zm6n6ZIlUesZMCDGFIJoNtKDXSJdoqRQbvPnwy9+Ad/5TjT/fPe78VRsR/sM6upiiIRrr22+/vDDI8G01bQkItKKqkgKZjYV+G+gJ/ALd/9+i/f7Ar8B3ge8CRzv7q+1tc+qSwqLF0eb9c03x506O+0U9/hvtlnX9z17djxDMG4cfOYzXd+fiHRbFR/mwsx6AlcCBwELgSfMbLq7P5e32WnAcnffwcxOAH4AHJ9WTCW1cGHc6/7d70bzz377RXKYOrV0TTcTJ2o4YxEpqzQfNd0bqHP3VwDM7GbgKCA/KRwFXJhbvg34mZmZp92mdeSRcaviQQfFN/stt4yHrIYNi7bsfv3iIa9ly6Itu0+fprJHj5j16tJLY1+bbQZ//nM074iIZFyaSWEbYEHe64XAB1rbxt03mNkKYDhQ4N7DLnrgATjzzFh+LpeXli4tfgKUlnbZBX7605j8pFqHcRAR6aA0r2aFelhb1gCK2QYzOwM4A2D06NGdi2bQoHhgCWLYhfPOi3LZsvh5662493/16riDZ+3auPtl0KBYXrcufhoaYkCz971PY+SISM1JMyksBPKHgRwFtJyeKtlmoZn1AjYD3mq5I3e/BrgGoqO5U9G8//0xNHJLI0fGj4iIpDp09hPAeDMba2Z9gBOA6S22mQ58Mrd8LHB/6v0JIiLSqtRqCrk+gjOBu4lbUq9397lm9m1gprtPB64DbjCzOqKGcEJa8YiISPtS7SF19xnAjBbrLshbXgN8PM0YRESkeOopFRGRRkoKIiLSSElBREQaKSmIiEgjJQUREWmUuaGzzWwp8K9OfnwEaQyh0XWKq2MUV8coro6p1riga7Ft5+7tPqmbuaTQFWY2s5ihY8tNcXWM4uoYxdUx1RoXlCc2NR+JiEgjJQUREWkKIc3VAAAHd0lEQVTU3ZLCNZUOoBWKq2MUV8coro6p1rigDLF1qz4FERFpW3erKYiISBu6TVIws6lmNs/M6szsnDIfe1sze8DMnjezuWZ2Vm79hWa2yMyeyv0clveZc3OxzjOzQ1KM7TUzezZ3/Jm5dZub2b1m9lKuHJZbb2b2k1xcz5jZXinFtFPeOXnKzFaa2Vcqcb7M7Hoz+7eZzclb1+HzY2afzG3/kpl9stCxShDXpWb2Qu7Yd5jZ0Nz6MWa2Ou+8/U/eZ96X+/3X5WIvNPFVV+Pq8O+t1P9fW4nr93kxvWZmT+XWl/N8tXZtqNzfmLvX/A8xdPfLwDigD/A0MKGMx98K2Cu3PBh4EZhAzE/9tQLbT8jF2BcYm4u9Z0qxvQaMaLHuh8A5ueVzgB/klg8D7iJmzJsMPFam393rwHaVOF/A/sBewJzOnh9gc+CVXDkstzwshbgOBnrlln+QF9eY/O1a7OdxYJ9czHcBh6YQV4d+b2n8fy0UV4v3LwMuqMD5au3aULG/se5SU9gbqHP3V9x9HXAzcFS5Du7uS9x9Vm75HeB5Yn7q1hwF3Ozua939VaCO+DeUy1HAr3PLvwb+X97633h4FBhqZlulHMsU4GV3b+uBxdTOl7v/g01nA+zo+TkEuNfd33L35cC9wNRSx+Xu97j7htzLR4nZDluVi22Iuz/icWX5Td6/pWRxtaG131vJ/7+2FVfu2/5xwE1t7SOl89XataFif2PdJSlsAyzIe72Qti/KqTGzMcBE4LHcqjNz1cDrkyoi5Y3XgXvM7EmLubABtnT3JRB/tMAWFYgrcQLN/7NW+nxBx89PJc7bZ4hvlImxZjbbzP5uZvvl1m2Ti6UccXXk91bu87Uf8Ia7v5S3ruznq8W1oWJ/Y90lKRRq9yv7bVdmNgj4A/AVd18JXA1sD+wJLCGqsFDeePd1972AQ4Evmtn+bWxb1vNoMY3rNCCZXLsazldbWouj3OftfGAD8LvcqiXAaHefCHwVuNHMhpQxro7+3sr9+zyR5l88yn6+ClwbWt20lRhKFlt3SQoLgW3zXo8CFpczADPrTfzSf+futwO4+xvu3uDuG4FraWryKFu87r44V/4buCMXwxtJs1Cu/He548o5FJjl7m/kYqz4+crp6PkpW3y5DsYjgJNzTRzkmmfezC0/SbTX75iLK7+JKZW4OvF7K+f56gV8DPh9XrxlPV+Frg1U8G+suySFJ4DxZjY29+3zBGB6uQ6ea7O8Dnje3S/PW5/fHn80kNwZMR04wcz6mtlYYDzRwVXquAaa2eBkmeionJM7fnL3wieBP+XFdWruDojJwIqkipuSZt/gKn2+8nT0/NwNHGxmw3JNJwfn1pWUmU0Fvg5Mc/f6vPUjzaxnbnkccX5eycX2jplNzv2Nnpr3byllXB39vZXz/+uBwAvu3tgsVM7z1dq1gUr+jXWl5zxLP0Sv/YtE1j+/zMf+EFGVewZ4KvdzGHAD8Gxu/XRgq7zPnJ+LdR5dvMOhjbjGEXd2PA3MTc4LMBz4G/BSrtw8t96AK3NxPQtMSvGcDQDeBDbLW1f280UkpSXAeuLb2GmdOT9EG39d7ufTKcVVR7QrJ39j/5Pb9pjc7/dpYBZwZN5+JhEX6ZeBn5F7oLXEcXX491bq/6+F4sqt/xXwuRbblvN8tXZtqNjfmJ5oFhGRRt2l+UhERIqgpCAiIo2UFEREpJGSgoiINFJSEBGRRkoK0m2YWYM1H321zdE3zexzZnZqCY77mpmN6MTnDrEYYXSYmc3oahwixehV6QBEymi1u+9Z7Mbu/j/tb5Wq/YAHiBE+H65wLNJNKClIt2dmrxHDHHwkt+okd68zswuBd939R2b2ZeBzxJhCz7n7CWa2OXA98RBgPXCGuz9jZsOJh6VGEk/oWt6xTgG+TAwJ/RjwBXdvaBHP8cC5uf0eBWwJrDSzD7j7tDTOgUhCzUfSnfRv0Xx0fN57K919b+Ip1R8X+Ow5wER3351IDgAXAbNz684jhlIG+BbwT48B1aYDowHMbBfgeGIQwj2BBuDklgdy99/TNPb/e4knaCcqIUg5qKYg3UlbzUc35ZVXFHj/GeB3ZvZH4I+5dR8ihkTA3e83s+FmthnR3POx3Pq/mNny3PZTgPcBT8SQN/SnaaCzlsYTQxkADPAYa18kdUoKIsFbWU4cTlzspwHfNLNdaXu44kL7MODX7n5uW4FYTIs6AuhlZs8BW1lMFfkld3+o7X+GSNeo+UgkHJ9XPpL/hpn1ALZ19weA/w8MBQYB/yDX/GNmBwDLPMbCz19/KDE9IsTAZsea2Ra59zY3s+1aBuLuk4C/EP0JPyQGhNtTCUHKQTUF6U76575xJ/7q7sltqX3N7DHii9KJLT7XE/htrmnIgCvc/e1cR/QvzewZoqM5Ger4IuAmM5sF/B2YD+Duz5nZN4iZ7noQI3Z+ESg01eheRIf0F4DLC7wvkgqNkirdXu7uo0nuvqzSsYhUmpqPRESkkWoKIiLSSDUFERFppKQgIiKNlBRERKSRkoKIiDRSUhARkUZKCiIi0uj/ADoTPtgrbDrFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd410a83b00>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = mean_scores\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(var)+1), var, 'r-')\n",
    "plt.plot( [0, len(var)+1], [0.5, 0.5], 'b-')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.51280000768601897,\n",
       " 0.537800008058548,\n",
       " 0.53880000807344919,\n",
       " 0.53890000807121397,\n",
       " 0.56090000839903953,\n",
       " 0.56890000851824885,\n",
       " 0.56790000850334765,\n",
       " 0.56590000847354527,\n",
       " 0.5909000088460743,\n",
       " 0.60590000906959174,\n",
       " 0.60490000905469055,\n",
       " 0.62890000941231849,\n",
       " 0.65490000979974861,\n",
       " 0.67990001017227764,\n",
       " 0.70590001055970786,\n",
       " 0.72490001084282996,\n",
       " 0.71890001075342302,\n",
       " 0.74200001109391456,\n",
       " 0.74610001115128399,\n",
       " 0.77010001150891183,\n",
       " 0.78720001175999643,\n",
       " 0.78820001177489762,\n",
       " 0.79320001184940336,\n",
       " 0.79320001184940336,\n",
       " 0.79130001181736587,\n",
       " 0.79030001180246467,\n",
       " 0.80630001204088331,\n",
       " 0.80720001205801961,\n",
       " 0.7992000119388103,\n",
       " 0.79820001192390921,\n",
       " 0.79820001192390921,\n",
       " 0.79820001192390921,\n",
       " 0.7973000119067728,\n",
       " 0.7973000119067728,\n",
       " 0.79930001193657518,\n",
       " 0.80430001201108103,\n",
       " 0.80430001201108103,\n",
       " 0.8163000121898949,\n",
       " 0.8163000121898949,\n",
       " 0.81340001214295621,\n",
       " 0.81340001214295621,\n",
       " 0.80740001205354928,\n",
       " 0.80930001208558677,\n",
       " 0.80830001207068558,\n",
       " 0.82430001230910421,\n",
       " 0.82530001232400541,\n",
       " 0.83130001241341234,\n",
       " 0.83140001241117711,\n",
       " 0.8524000127241016,\n",
       " 0.8514000127092004,\n",
       " 0.84840001266449694,\n",
       " 0.85440001275390387,\n",
       " 0.85440001275390387,\n",
       " 0.85540001276880506,\n",
       " 0.85640001278370614,\n",
       " 0.86940001297742131,\n",
       " 0.87140001300722358,\n",
       " 0.87140001300722358,\n",
       " 0.87550001306459313,\n",
       " 0.88350001318380234,\n",
       " 0.88350001318380234,\n",
       " 0.89140001330524687,\n",
       " 0.88430001320317386,\n",
       " 0.88430001320317386,\n",
       " 0.89520001336932187,\n",
       " 0.89620001338422295,\n",
       " 0.89610001338645817,\n",
       " 0.89610001338645817,\n",
       " 0.89610001338645817,\n",
       " 0.89510001337155698,\n",
       " 0.89410001335665579,\n",
       " 0.89710001340135936,\n",
       " 0.87620001308619977,\n",
       " 0.87620001308619977,\n",
       " 0.87620001308619977,\n",
       " 0.8642000129073858,\n",
       " 0.86220001287758352,\n",
       " 0.85630001278594137,\n",
       " 0.85530001277104017,\n",
       " 0.83930001253262165,\n",
       " 0.81430001216009262,\n",
       " 0.80520001202821734,\n",
       " 0.80520001202821734,\n",
       " 0.78410001171752808,\n",
       " 0.76310001140460371,\n",
       " 0.76310001140460371,\n",
       " 0.7731000115536153,\n",
       " 0.77410001156851649,\n",
       " 0.76810001147910956,\n",
       " 0.74410001112148161,\n",
       " 0.74410001112148161,\n",
       " 0.73210001094266774,\n",
       " 0.7261000108532607,\n",
       " 0.7261000108532607,\n",
       " 0.7171000107191503,\n",
       " 0.72410001082345843,\n",
       " 0.72510001083835962,\n",
       " 0.72510001083835962,\n",
       " 0.73710001101717348,\n",
       " 0.73110001092776655,\n",
       " 0.70510001054033633,\n",
       " 0.69210001034662127,\n",
       " 0.69110001033172008,\n",
       " 0.690100010316819,\n",
       " 0.66810000998899344]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores[1595: 1700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_agnt, agnt in enumerate(maddpg.maddpg_agent):\n",
    "    torch.save(agnt.actor.state_dict(),         'final_ckpt_actor_{}.pth'.format(num_agnt))\n",
    "    torch.save(agnt.target_actor.state_dict(),  'final_ckpt_target_actor_{}.pth'.format(num_agnt))\n",
    "    torch.save(agnt.critic.state_dict(),        'final_ckpt_critic_{}.pth'.format(num_agnt))\n",
    "    torch.save(agnt.target_critic.state_dict(), 'final_ckpt_target_critic_{}.pth'.format(num_agnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
